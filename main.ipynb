{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Specify path to the dataset\n",
    "train_dir = '/kaggle/input/shopee-product-detection-open/train/train/train/'\n",
    "test_dir = '/kaggle/input/shopee-product-detection-open/test/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count number of images\n",
    "def count_images(location):\n",
    "    counter = 0\n",
    "    for path, subdirs, files in os.walk(location):\n",
    "        for name in files:\n",
    "            if name.endswith(\".jpg\"):\n",
    "                counter = counter + 1\n",
    "    \n",
    "    return(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 105390\n",
      "Total test images: 12192\n"
     ]
    }
   ],
   "source": [
    "# Count number of images\n",
    "total_train = count_images(train_dir)\n",
    "total_test = count_images(test_dir)\n",
    "\n",
    "print(\"Total training images:\", total_train)\n",
    "print(\"Total test images:\", total_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify hyperparameters\n",
    "batch_size = 64\n",
    "epochs = 2\n",
    "IMG_HEIGHT = 299\n",
    "IMG_WIDTH = 299\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image generator\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 105390 images belonging to 42 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define flow from the training data\n",
    "train_generator = train_image_generator.flow_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    directory=train_dir,\n",
    "    shuffle=True,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12192 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define flow from the test data\n",
    "test_generator = test_image_generator.flow_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    directory=test_dir,\n",
    "    shuffle=False,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Create the base model from the pre-trained model InceptionResNetV2\n",
    "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "base_model = tf.keras.applications.InceptionResNetV2(\n",
    "    input_shape=IMG_SHAPE,\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  780\n"
     ]
    }
   ],
   "source": [
    "# Show the number of layers in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a classification head\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(42)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_resnet_v2 (Model)  (None, 8, 8, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 42)                64554     \n",
      "=================================================================\n",
      "Total params: 54,401,290\n",
      "Trainable params: 54,340,746\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model.h5',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1646/1646 [==============================] - 3175s 2s/step - loss: 0.9469 - accuracy: 0.7424\n",
      "Epoch 2/2\n",
      "1646/1646 [==============================] - 2860s 2s/step - loss: 0.5393 - accuracy: 0.8468\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction for test data\n",
    "predictions = np.argmax(model.predict(test_generator), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filenames of test data\n",
    "filenames = test_generator.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of test images for submission\n",
    "test = pd.read_csv('/kaggle/input/shopee-product-detection-open/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission file\n",
    "submission=pd.DataFrame({\"filename\": filenames, \"category\": predictions})\n",
    "submission.category = submission.category.astype('str')\n",
    "submission['filename'] = submission.apply(lambda row: row[0][5:], axis=1)\n",
    "submission['category'] = submission.apply(lambda row: row[1].zfill(2), axis=1)\n",
    "submission = pd.merge(test[['filename']], submission, on='filename', how='left')\n",
    "submission.to_csv('submission.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
